{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43dddb8f888c5df2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "___\n",
    "<h1> Machine Learning </h1>\n",
    "<h2> M. Sc. in Electrical and Computer Engineering </h2>\n",
    "<h3> Instituto Superior de Engenharia / Universidade do Algarve </h3>\n",
    "\n",
    "[MEEC](https://ise.ualg.pt/en/curso/1477) / [ISE](https://ise.ualg.pt) / [UAlg](https://www.ualg.pt)\n",
    "\n",
    "Pedro J. S. Cardoso (pcardoso@ualg.pt)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff5fab68e164de",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Kaggle competition: Digit Recognizer\n",
    "In this notebook we will see how to compete in a Kaggle competition. We will use the \"Digit Recognizer: Learn computer vision fundamentals with the famous MNIST data\". All information can be found at  https://www.kaggle.com/competitions/digit-recognizer/overview.\n",
    "\n",
    "MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    "In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images.  We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.\n",
    "\n",
    "In this tutorial we will use the KNN classifier to classify the digits. We will use the training data to train the classifier and the test data to test the classifier. The test data does not have the labels, so we will not be able to evaluate the classifier. We will submit the results to Kaggle and see how well we did.\n",
    "\n",
    "More advanced techniques exist, but we will not cover them in this tutorial. For instance, we could use a convolutional neural network (CNN) to classify the digits. However, this is beyond the scope of this course. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7210a41a6ad6b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load the data\n",
    "So, start by downloading the data from Kaggle (there is already a copy on our repository). To compete you will need to create an account at Kaggle.\n",
    "\n",
    "After downloading the data, we must load it into Python. We will use the Pandas library to load the data into a dataframe.\n",
    "\n",
    "_Note: the zip file contains a csv file containing the training data_ "
   ]
  },
  {
   "cell_type": "code",
   "id": "6d28a82a8d1aab04",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv(\"./data/digit-recognizer/train.csv.zip\")\n",
    "\n",
    "# show the first 5 rows\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5efccbbe046ce2ad",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can see that there are 785 columns. The first column is the label (the digit) and the remaining 784 columns are the pixels of the image (28x28). The values of the pixels are between 0 and 255. The label is the digit that the image represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f809ee842344a3ac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Explore the data (basic)\n",
    "\n",
    "Let's see the distribution of the labels."
   ]
  },
  {
   "cell_type": "code",
   "id": "f5306f19d31c5031",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df['label'].groupby(df['label']).count()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "22c9d0ac06331e94",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can see that the distribution is \"almost\" uniform, with around 4200 images for each digit."
   ]
  },
  {
   "cell_type": "code",
   "id": "2cb8be2ef93657",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df['label'].groupby(df['label']).count().plot(kind='bar')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "104d93eb44d6e305",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's see the distribution of the pixels by computing the mean of each pixel for each digit."
   ]
  },
  {
   "cell_type": "code",
   "id": "b2ad87e9a8c3893c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# get the mean of each pixel for each digit\n",
    "mean_pixels_value_by_digit = df.iloc[:, 1:].groupby(df['label']).mean()\n",
    "\n",
    "mean_pixels_value_by_digit"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c192dd1499bb27f5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# plot the mean of each pixel for each digit\n",
    "for i in range(10):\n",
    "    digit = mean_pixels_value_by_digit.iloc[i].values.reshape(28,28)\n",
    "    plt.imshow(digit, cmap=plt.cm.binary, interpolation='nearest')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b093842cdc357bff",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can see that the digits are quite different...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed699d10df4804ed",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prepare the data\n",
    "\n",
    "To continue, let us get the data and the target from the dataframe. If you go up, you can see that the first column is the label. We will drop that column and get the remaining columns as the data. The target will be the label column.\n",
    "\n",
    "_Note: The pandas' drop function, with axis=1 and corresponding `label` column, drops the `label` column._"
   ]
  },
  {
   "cell_type": "code",
   "id": "78efa158ca946db0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "data = df.drop(\"label\", axis=1)\n",
    "data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7d760e0425abd970",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To get the target, we can use the `label` column.\n",
    "\n",
    "_Note: The `label` column is the first column of the dataframe. We can access it using `df[\"label\"]`. This returns a pandas series._"
   ]
  },
  {
   "cell_type": "code",
   "id": "9589b675bbddc9b3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "target = df[\"label\"]\n",
    "target.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9705cf1505d0f8eb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's plot the first 5 digits.\n",
    "\n",
    "_Note:_\n",
    "    _- to access a row of a dataframe, we can use the `iloc` function. For instance, `data.iloc[0]` returns the first row of the dataframe._ \n",
    "    _-To access a column, we can use `data.iloc[:,0]` which returns the first column of the dataframe._\n",
    "    _-To access a cell, we can use `data.iloc[0,0]` which returns the first cell of the dataframe._\n",
    "    _- the `values` atribute returns the values of the dataframe as a numpy array._\n",
    "    _- the `reshape` function of a numpy array reshapes the array. For instance, `data.iloc[0].values.reshape(28,28)` returns the first row of the dataframe as a numpy array with 28 rows and 28 columns._"
   ]
  },
  {
   "cell_type": "code",
   "id": "b91afa3f88212df1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for i in range(5):\n",
    "    # get the digit at index i of the data and reshape it to 28x28\n",
    "    digit = data.iloc[i].values.reshape(28, 28)\n",
    "\n",
    "    # plot the digit\n",
    "    plt.imshow(digit, cmap=plt.cm.binary, interpolation='nearest')\n",
    "    plt.title(f\"Digit: {target.iloc[i]}\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "27b576dd14bba65c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Split the data into training and validation sets\n",
    "\n",
    "Split the data into training and validation sets is fundamental to evaluate the performance of the classifier, as usual, we will use the training set to train the classifier and the validation set to evaluate the performance of the classifier. A better approach is to use cross-validation, but we will not cover that in this tutorial. \n",
    "\n",
    "![train_validate_test](train_validate_test.png)\n",
    "\n",
    "Remember in this case the test set is the one provided by Kaggle and does not have the labels, so we will not be able to directly evaluate the classifier. We will submit the results to Kaggle and see how well we did.\n",
    "\n",
    "To split the data, we will use the `train_test_split` function from the `sklearn.model_selection` module, and use 20% of the data for validating and 80% for training. The `random_state` parameter ensures that we always get the same split and the `stratify` parameter ensures that the distribution of the labels is the same in the training and validate sets."
   ]
  },
  {
   "cell_type": "code",
   "id": "e1ef46e59a989bcc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data.values, \n",
    "                                                  target.values, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=target)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "16cf4aa76ef83e1b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(f\"X_train shape: {X_train.shape}\\ny_train shape: {y_train.shape}\\nX_val shape: {X_val.shape}\\ny_val shape: {y_val.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "66dc08a1c89c2594",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Simple classifier: using KNN\n",
    "\n",
    "In this tutorial we will use the KNN classifier to classify the digits. So, the first step is to import the KNN classifier from the `sklearn.neighbors` module and create an instance of the classifier. We will use 5 neighbors (why 5? because!)."
   ]
  },
  {
   "cell_type": "code",
   "id": "18e03565a8507501",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c4fc90637cd27488",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To evaluate the classifier, we can use the `score` function of the classifier. This function returns the accuracy of the classifier over the validation set. Remember, the accuracy is the number of correct predictions divided by the number of predictions, i.e.,\n",
    "$$ accuracy = \\frac{number\\ of\\ correct\\ predictions}{number\\ of\\ predictions} = \\frac{TP + TN}{TP + TN + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "id": "fc05fa9cef734392",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "knn.score(X_val, y_val)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "785076cd834d62ef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If we want to see the predictions probabilities, we can use the `predict_proba` function of the classifier. This function returns the probabilities of each class for each sample. For instance, if we have 10 classes and 5 samples, the output will have the shape (5, 10). The sum of the probabilities for each sample is 1."
   ]
  },
  {
   "cell_type": "code",
   "id": "315d7d221e2ea3cd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "knn.predict_proba(X_val[:5])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e4b652a8ea51ff36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can see that the accuracy is around 97%. This means that the classifier is able to correctly classify 97% of the digits. Considering the simplicity of the classifier, this isn't bad! But, **YOU** can do better...\n",
    "\n",
    "Let's see some examples of the classifier in action."
   ]
  },
  {
   "cell_type": "code",
   "id": "433a5d1855bbf1fa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# get the predictions for the first 5 digits of the validation set\n",
    "pred = knn.predict(X_val[:5, :])\n",
    "\n",
    "for i in range(5):\n",
    "    # get the digit at index i of the test set and reshape it to 28x28\n",
    "    digit = X_val[i, :].reshape(28, 28)\n",
    "    \n",
    "    # plot the digit\n",
    "    plt.imshow(digit, cmap=plt.cm.binary, interpolation='nearest')\n",
    "    \n",
    "    # insert a title with the predicted and real labels\n",
    "    real = y_val[i]\n",
    "    plt.title(f\"Predicted: {pred[i]} ..... Real: {real}\".center(50, '.'))\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f24a6378fd245020",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Where were the errors?\n",
    "\n",
    "Let us get the indeces where the classifier made an error, i.e., where the predicted label is different from the real label."
   ]
  },
  {
   "cell_type": "code",
   "id": "daae8e0ebde2fdc2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pred = knn.predict(X_val)\n",
    "errors_idx = [i for i in range(len(pred)) if pred[i] != y_val[i]]\n",
    "print(f\"Number of errors: {len(errors_idx)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2d6dcdb0af7feda7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And let's plot the errors."
   ]
  },
  {
   "cell_type": "code",
   "id": "1bac84b2d36b42d0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plots_per_row = 5\n",
    "n_rows = len(errors_idx) // plots_per_row + 1\n",
    "\n",
    "# plot the errors using subplots matrix of n_rows x plots_per_row\n",
    "fig, ax = plt.subplots(n_rows, plots_per_row, figsize=(15, n_rows*5))\n",
    "\n",
    "for i in range(len(errors_idx)):\n",
    "    # get the index of the error\n",
    "    err_idx = errors_idx[i]\n",
    "    \n",
    "    # get the row and column of the subplot\n",
    "    row = i//plots_per_row\n",
    "    col = i%plots_per_row\n",
    "\n",
    "    # get the digit at index i of the test set and reshape it to 28x28\n",
    "    digit = X_val[err_idx, :].reshape(28, 28)\n",
    "    \n",
    "    # plot the digit\n",
    "    ax[row, col].imshow(digit, cmap=plt.cm.binary)\n",
    "    \n",
    "    # insert a title with the predicted and real labels\n",
    "    real = y_val[err_idx]\n",
    "    ax[row, col].set_title(f\"{err_idx}: Predicted: {pred[err_idx]} ..... Real: {real}\")\n",
    "    \n",
    "    # remove the axis - we don't need it\n",
    "    ax[i//plots_per_row, i%plots_per_row].axis('off')    \n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "97ca024e0cb7a40a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Test the classifier with the test data\n",
    "\n",
    "Now, let's test the classifier with the test data. The test data does not have the labels, so we will not be able to evaluate the classifier, except by submitting the results to Kaggle and see how well we did.\n",
    "\n",
    "So, let's load the test data."
   ]
  },
  {
   "cell_type": "code",
   "id": "66e1f13318a46700",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df_test = pd.read_csv(\"./data/digit-recognizer/test.csv.zip\")\n",
    "df_test.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "15378f6d3b6d27b1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can see that the test data has 784 columns, i.e., 784 pixels (28x28). \n",
    "\n",
    "So, let's get the data from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "id": "e4ca43cac84e7e4a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "X_test = df_test.values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5624faff39193338",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "which has the shape"
   ]
  },
  {
   "cell_type": "code",
   "id": "934fcb7c5b15483e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "n_rows, n_cols = X_test.shape\n",
    "print(f\"n_rows: {n_rows}\\nn_cols: {n_cols}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e98f4cfb02d0bb0b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compute the predictions for the test data."
   ]
  },
  {
   "cell_type": "code",
   "id": "72c4a2e0709bc387",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pred = knn.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e80de2664b15421",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Which has the shape"
   ]
  },
  {
   "cell_type": "code",
   "id": "2762c645da0ac52e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pred.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1f8703d39d238746",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Build a dataframe with the predictions and the image id. Look at the `sample_submission.csv` file to see the format of the submission file:\n",
    "```\n",
    "ImageId,Label\n",
    "1,0\n",
    "2,0\n",
    "3,0\n",
    "etc.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "5bf2092d5846ff23",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# create an empty dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# add the ImageId column\n",
    "df['ImageId'] = range(1, n_rows+1)\n",
    "\n",
    "# add the Label column\n",
    "df['Label'] = pred\n",
    "\n",
    "# show the first 5 rows\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "772e40876aba90a3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Save the dataframe to a csv file.\n",
    "\n",
    "_Note: the `index=False` parameter ensures that the index is not saved to the csv file._"
   ]
  },
  {
   "cell_type": "code",
   "id": "f005869204c5030f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df.to_csv(\"./data/digit-recognizer/submission.csv.zip\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "272498d05130293d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, go to Kaggle and submit the file `submission.csv.zip` and see how well you did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ef619d61a9a3a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Next steps\n",
    "\n",
    "- Try to improve the classifier. For instance, you can try to use a different number of neighbors, or use a different classifier.\n",
    "- Try to use cross-validation and grid search to find the best parameters for the classifier.\n",
    "- Try to use other classifiers. For instance, you can try to use a decision tree classifier or a random forest classifier.\n",
    "- Try to use the CNN classifier. Online, you can find many tutorial... \n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "id": "af51436f73abddeb",
   "metadata": {
    "collapsed": false
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d6feb94e-d9a0-456d-8e2f-0c741edcb476",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:micromamba-metal]",
   "language": "python",
   "name": "conda-env-micromamba-metal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
