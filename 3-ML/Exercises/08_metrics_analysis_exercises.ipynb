{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "___\n",
    "<h1> Machine Learning </h1>\n",
    "<h2> M. Sc. in Electrical and Computer Engineering </h2>\n",
    "<h3> Instituto Superior de Engenharia / Universidade do Algarve </h3>\n",
    "\n",
    "[MEEC](https://ise.ualg.pt/en/curso/1477) / [ISE](https://ise.ualg.pt) / [UAlg](https://www.ualg.pt)\n",
    "\n",
    "Pedro J. S. Cardoso (pcardoso@ualg.pt)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Classification metrics exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##  Exercise 1\n",
    "\n",
    "Without using the `sklearn.metrics` module, or other library, compute the following metrics:\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f1-score\n",
    "- confusion matrix\n",
    "- plot the confusion matrix\n",
    "\n",
    "for the following predictions and targets:\n",
    "\n",
    "```python\n",
    "predictions = [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
    "targets = [1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T11:37:24.500839Z",
     "start_time": "2023-10-09T11:37:24.374743Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# compute TP, FP, TN, FN\n",
    "\n",
    "TP = ?? # TODO\n",
    "FP = ?? # TODO\n",
    "TN = ?? # TODO\n",
    "FN = ?? # TODO\n",
    "\n",
    "print(f\"TP={TP}, FP={FP}, TN={TN}, FN={FN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "accuracy = ?? # TODO\n",
    "print(f\"accuracy={accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# precision\n",
    "precision = ?? # TODO\n",
    "print(f\"precision={precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# recall\n",
    "recall = ?? # TODO\n",
    "print(f\"recall={recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# f1-score\n",
    "f1_score = ?? # TODO\n",
    "print(f\"f1_score={f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix = ?? # TODO\n",
    "print(f\"confusion_matrix=\\n{confusion_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "?? # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "Let y be the target values and y1 and y2 the predictions of two different models, where:\n",
    "\n",
    "```python\n",
    "y = [1, 1, 0, 1, 0, 0, 1, 0, 0, 1]\n",
    "y1 = [1, 0, 0, 1, 0, 1, 1, 1, 0, 0]\n",
    "y2 = [1, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
    "```\n",
    "\n",
    "1. Which model is better? Why?\n",
    "2. What if 1 is having a contagious disease and 0 is not having the disease?\n",
    "3. What if 1 is a spam email and 0 is a non-spam email?\n",
    "4. What if 1 is a fraudulent transaction and 0 is a non-fraudulent transaction?\n",
    "5. What if 1 is a cancer patient and 0 is a non-cancer patient?\n",
    "6. What if 1 is a relevant document and 0 is a non-relevant document?\n",
    "7. What if 1 is the person is considered responsible for a crime and 0 is a non-responsible person?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# load skleran metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "y = [1, 1, 1, 1, 0, 0, 1, 0, 0, 1]\n",
    "y1 = [1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
    "y2 = [1, 1, 0, 1, 1, 0, 0, 0, 0, 1]\n",
    "\n",
    "accuracy_score(y, y1), accuracy_score(y, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "precision_score(y, y1), precision_score(y, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "recall_score(y, y1), recall_score(y, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f1_score(y, y1), f1_score(y, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Case by case:\n",
    "\n",
    "1. Which model is better? Why?\n",
    "if we consider the accuracy, the models are equal. However, if we consider the precision the second model is better but if we consider the recall the first model is better. So, it depends on the application.\n",
    "\n",
    "2. What if 1 is having a contagious disease and 0 is not having the disease?\n",
    "...\n",
    "\n",
    "3. What if 1 is a spam email and 0 is a non-spam email?\n",
    "...\n",
    "\n",
    "4. What if 1 is a fraudulent transaction and 0 is a non-fraudulent transaction?\n",
    "...\n",
    "\n",
    "5. What if 1 is a cancer patient and 0 is a non-cancer patient?\n",
    "...\n",
    "\n",
    "6. What if 1 is a relevant document and 0 is a non-relevant document?\n",
    "...\n",
    "\n",
    "7. What if 1 is the person is considered responsible for a crime and 0 is a non-responsible person?\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Exercise 3\n",
    "\n",
    "Change the KNN model to use 5 and 15 neighbors and evaluate the model using the metrics from the previous exercise. Take a look at the classification report and confusion matrix. What do you notice? Which model is better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
