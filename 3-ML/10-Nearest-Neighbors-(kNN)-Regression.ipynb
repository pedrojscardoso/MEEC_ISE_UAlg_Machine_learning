{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $k$-Nearest Neighbors (kNN): Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:53:10.864435Z",
     "start_time": "2019-05-16T10:53:08.961376Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# !pip3 install mglearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import mglearn.plots\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Neighbors Regression\n",
    "\n",
    "There is also a regression variant of the k-nearest neighbors algorithm. Again, let’s start by using a single nearest neighbor, this time using the wave dataset. \n",
    "\n",
    "The prediction using a single neighbor (1-NN) is just the target value of the nearest neighbor. When using multiple nearest neighbors for regression, the prediction is the average (or mean) of the relevant neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:53:29.482189Z",
     "start_time": "2019-05-16T10:53:29.473198Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "n_samples = 50\n",
    "a, b = -10, 10\n",
    "\n",
    "# set of \"x's\"\n",
    "timeline = np.linspace(a, b, n_samples).reshape(-1, 1)\n",
    "print(timeline)\n",
    "# set a 'wave'\n",
    "def make_wave(timeline):\n",
    "    return 10 * np.cos(timeline) + 5 * np.random.rand(len(timeline))\n",
    "\n",
    "wave = make_wave(timeline.T[0])\n",
    "\n",
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:53:31.602111Z",
     "start_time": "2019-05-16T10:53:31.448268Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(timeline, wave, linestyle='None', marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, split the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:53:36.740251Z",
     "start_time": "2019-05-16T10:53:36.735238Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(timeline, wave, test_size=.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x_train, y_train, linestyle=\"none\", marker='o', c=\"red\")\n",
    "ax.plot(x_test, y_test, linestyle=\"none\", marker='o', c=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:53:37.860170Z",
     "start_time": "2019-05-16T10:53:37.856174Z"
    }
   },
   "outputs": [],
   "source": [
    "knr = KNeighborsRegressor(\n",
    "        n_neighbors=3, \n",
    "        weights='distance').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:53:43.077059Z",
     "start_time": "2019-05-16T10:53:43.071052Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_test)\n",
    "print(y_test)\n",
    "knr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see compute the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:53:44.631458Z",
     "start_time": "2019-05-16T10:53:44.624481Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = knr.predict(x_test)\n",
    "\n",
    "delta = y_pred - y_test\n",
    "delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`score`  - Returns the coefficient of determination $R^2$ of the prediction.\n",
    "\n",
    "Coefficient $R^2$ is defined as $(1 - u/v)$, where $u$ is the residual sum of squares `((y_true - y_pred) ** 2).sum()` and $v$ is the total sum of squares `((y_true - y_true.mean()) ** 2).sum()`. \n",
    "\n",
    "The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "\n",
    "A constant model that always predicts the expected value of $y$, disregarding the input features, would get a $R^2$ score of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:53:49.237832Z",
     "start_time": "2019-05-16T10:53:49.231837Z"
    }
   },
   "outputs": [],
   "source": [
    "knr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x_train, y_train, linestyle=\"none\", marker='o', c=\"red\")\n",
    "ax.plot(x_test, y_test, linestyle=\"none\", marker='o', c=\"blue\")\n",
    "ax.plot(x_test, y_pred, linestyle=\"none\", marker='o', c=\"green\")\n",
    "ax.legend([\"train\", \"test\", \"pred\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:53:55.230065Z",
     "start_time": "2019-05-16T10:53:50.823566Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = np.arange(a, b, .01).reshape(-1, 1)\n",
    "\n",
    "K = 30\n",
    "fig = plt.figure(figsize=(10 * 2, 5 * K))\n",
    "\n",
    "im_idx = 0\n",
    "\n",
    "for nn in range(1, K, 2):\n",
    "    #  weights='uniform'\n",
    "    # ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "    knr = KNeighborsRegressor(n_neighbors=nn, weights='uniform').fit(x_train, y_train)\n",
    "    y = knr.predict(X)\n",
    "\n",
    "    im_idx += 1\n",
    "    ax = fig.add_subplot(K - 1, 2, im_idx)\n",
    "    ax.plot(timeline, wave, label='original')\n",
    "    ax.plot(x_train, y_train, linestyle=\"none\", marker='o', c=\"red\")\n",
    "    ax.plot(X, y, label=f'nn = {nn}, weights = uniform, r2 = {knr.score(x_test, y_test)}')\n",
    "    ax.legend()\n",
    "\n",
    "    # weights='distance'\n",
    "    # ‘distance’ : weight points by the inverse of their distance. In this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "    knr = KNeighborsRegressor(n_neighbors=nn, weights='distance').fit(x_train, y_train)\n",
    "    y = knr.predict(X)\n",
    "    \n",
    "    im_idx += 1\n",
    "    ax = fig.add_subplot(K - 1, 2, im_idx)\n",
    "    ax.plot(timeline, wave, label='original')\n",
    "    ax.plot(X, y, label=f'nn = {nn}, weights = distance,  r2= {knr.score(x_test, y_test)} ')\n",
    "    ax.plot(x_train, y_train, linestyle=\"none\", marker='o', c=\"red\")\n",
    "    ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how it behaves outside the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T10:55:32.620224Z",
     "start_time": "2019-05-16T10:55:30.747120Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# supposing a<0\n",
    "X = np.arange(2 * a, 2 * b, .1).reshape(-1, 1)\n",
    "\n",
    "K = 15\n",
    "fig = plt.figure(figsize=(10 * 2, 5 * K))\n",
    "\n",
    "im_idx = 0\n",
    "\n",
    "for nn in range(1, K, 2):\n",
    "    #  weights='uniform'\n",
    "    # ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "    knr = KNeighborsRegressor(n_neighbors=nn, weights='uniform').fit(timeline, wave)\n",
    "    y = knr.predict(X)\n",
    "\n",
    "    im_idx += 1\n",
    "    ax = fig.add_subplot(K - 1, 2, im_idx)\n",
    "    ax.plot(timeline, wave, label='original')\n",
    "    ax.plot(X, y, label='nn = {}'.format(nn))\n",
    "    ax.legend()\n",
    "\n",
    "    # weights='distance'\n",
    "    # ‘distance’ : weight points by the inverse of their distance. In this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "    knr = KNeighborsRegressor(n_neighbors=nn, weights='distance').fit(timeline, wave)\n",
    "    y = knr.predict(X)\n",
    "    \n",
    "    im_idx += 1\n",
    "    ax = fig.add_subplot(K - 1, 2, im_idx)\n",
    "    ax.plot(timeline, wave, label='original')\n",
    "    ax.plot(X, y, label='nn = {}'.format(nn))\n",
    "    ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "277px",
    "width": "344px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
