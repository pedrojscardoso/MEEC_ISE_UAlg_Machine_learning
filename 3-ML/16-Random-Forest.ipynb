{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "<h1> Machine Learning </h1>\n",
    "<h2> M. Sc. in Electrical and Computer Engineering </h2>\n",
    "<h3> Instituto Superior de Engenharia / Universidade do Algarve </h3>\n",
    "\n",
    "[MEEC](https://ise.ualg.pt/en/curso/1477) / [ISE](https://ise.ualg.pt) / [UAlg](https://www.ualg.pt)\n",
    "\n",
    "Pedro J. S. Cardoso (pcardoso@ualg.pt)\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "## Classification\n",
    "\n",
    "Let us start, again, with the iris dataset. Following the same flow, it is now easy to train a Decision Tree Model\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data,\n",
    "                                                    iris.target,\n",
    "                                                    train_size=.75,\n",
    "                                                    random_state=42)\n",
    "\n",
    "dtc = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a perfect score on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = dtc.score(X_train, y_train)\n",
    "score   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and also in test...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = dtc.score(X_test, y_test)\n",
    "score   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ater this we can plot the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (30, 30))\n",
    "\n",
    "tree.plot_tree(\n",
    "    dtc,\n",
    "    feature_names = iris.feature_names,\n",
    "    class_names=iris.target_names,\n",
    "    filled = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the tree to predict some of the test examples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.feature_names, '\\n', X_test[:5], '\\n', iris.target_names[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do some cross validation\n",
    "(https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) using a stratified shuffle split (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) that is not so perfect!\n",
    "\n",
    "In the first example, then minimum number of samples required to be at a leaf node is 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedShuffleSplit(\n",
    "    n_splits=10,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "scores = cross_val_score(\n",
    "    clf,\n",
    "    iris.data, iris.target, \n",
    "    cv=skf\n",
    ")\n",
    "\n",
    "print(f'scores:{scores}\\nmu:{scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second example, we increase minimum number of samples required to be at a leaf node to be 3, giving a slight increase in performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(\n",
    "    random_state=1,\n",
    "    min_samples_leaf = 3,\n",
    ")\n",
    "\n",
    "scores = cross_val_score(\n",
    "    clf,\n",
    "    iris.data, iris.target, \n",
    "    cv=skf\n",
    ")\n",
    "\n",
    "print(f'scores:{scores}\\nmu:{scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "\n",
    "In this example we'll use the Boston dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    test_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the rergressor and do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(\n",
    "    random_state=0\n",
    ").fit(X_train, y_train)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly, we score it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = dtr.score(X_test, y_test)\n",
    "score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtr.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(y_test, c='b')\n",
    "plt.plot(y_pred, c='g')\n",
    "plt.plot(np.abs(y_pred-y_test), c='r')\n",
    "\n",
    "plt.legend([\"test\", \"pred\", \"$\\Delta = |y_i-\\hat{y_i}|$\"])\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (800, 100))\n",
    "\n",
    "tree.plot_tree(\n",
    "    dtr,\n",
    "    feature_names=boston.feature_names,\n",
    "    filled=True,\n",
    "    fontsize=12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be more sure, let us do a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"tree.png\", dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(\n",
    "    n_splits=5, \n",
    "    shuffle=True, \n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "reg = DecisionTreeRegressor(\n",
    "    random_state=1,\n",
    "    min_samples_leaf = 3,\n",
    ")\n",
    "\n",
    "scores = cross_val_score(\n",
    "    reg,\n",
    "    boston.data, boston.target, \n",
    "    cv=kfold\n",
    ")\n",
    "\n",
    "print(f'scores:{scores}\\nmu:{scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide's example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "n = 25\n",
    "a, b = 0, 10\n",
    "x = np.linspace(a, b, n)\n",
    "y = np.sin(x)\n",
    "plt.plot(x, y, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(min_samples_leaf=1).fit(x.reshape(-1, 1), y)\n",
    "\n",
    "x_hat = np.linspace(a, b, 100).reshape(-1, 1)\n",
    "y_hat = model.predict(x_hat)\n",
    "plt.plot(x, y, \".\")\n",
    "plt.plot(x_hat, y_hat)\n",
    "\n",
    "plt.legend([\"data\", \"approx.\"])\n",
    "plt.title(\"Decision regression tree (min_samples_leaf=1)\")\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(min_samples_leaf=2).fit(x.reshape(-1, 1), y)\n",
    "\n",
    "x_hat = np.linspace(a, b, 100).reshape(-1, 1)\n",
    "y_hat = model.predict(x_hat)\n",
    "plt.plot(x, y, \".\")\n",
    "plt.plot(x_hat, y_hat)\n",
    "\n",
    "plt.legend([\"data\", \"approx.\"])\n",
    "plt.title(\"Decision regression tree (min_samples_leaf=2)\")\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (30, 10))\n",
    "\n",
    "tree.plot_tree(\n",
    "    model,\n",
    "    feature_names=[\"x\"],\n",
    "    filled=True,\n",
    "    fontsize=12\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data,\n",
    "                                                    iris.target, \n",
    "                                                    train_size=.75,\n",
    "                                                    random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        n_jobs=-1,\n",
    "        min_samples_leaf = 1,\n",
    "        max_leaf_nodes = 5,\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = rfc.score(X_train, y_train)\n",
    "print(f'scores:{scores}\\nmu:{scores.mean()}')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = rfc.score(X_test, y_test)\n",
    "print(f'scores:{scores}\\nmu:{scores.mean()}')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(\n",
    "    n_splits=5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rfc = RandomForestClassifier(\n",
    "        n_estimators=20,\n",
    "        n_jobs=-1,\n",
    "        min_samples_leaf = 1,\n",
    "#         max_leaf_nodes = 5,\n",
    ")\n",
    "\n",
    "scores = cross_val_score(\n",
    "    rfc,  \n",
    "    iris.data, \n",
    "    iris.target, \n",
    "    cv=sss\n",
    ")\n",
    "\n",
    "print(f'scores:{scores}\\nmu:{scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=1,\n",
    "                                                    test_size=0.1)\n",
    "\n",
    "rfr = RandomForestRegressor( \n",
    "        n_estimators=10,\n",
    "        n_jobs=-1,\n",
    "        random_state=0).fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfr.predict(X_test)\n",
    "\n",
    "score = rfr.score(X_test, y_test)\n",
    "score        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(y_test, c='b')\n",
    "plt.plot(y_pred, c='g')\n",
    "plt.plot(np.abs(y_pred-y_test), c='r')\n",
    "\n",
    "plt.legend([\"test\", \"pred\", \"$\\Delta = |y_i-\\hat{y_i}|$\"])\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(\n",
    "    n_splits=5, \n",
    "    shuffle=True, \n",
    "    random_state=42\n",
    ")\n",
    "scores = cross_val_score(rfr,  boston.data, boston.target, cv=kfold)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
